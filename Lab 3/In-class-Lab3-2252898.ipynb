{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language Model and Application for Spelling Error Correction\n",
        "\n",
        "### Objective:\n",
        "Develop a simple English syntax error correction program.\n",
        "\n",
        "### Tasks:\n",
        "a) Build a language model based on n-grams using the Laplace smoothing method for the following models:\n",
        "  - 1-gram\n",
        "  - 2-gram\n",
        "  - 3-gram\n",
        "\n",
        "b) Calculate the probability of a sentence and compute the Perplexity of a sentence based on 1-gram, 2-gram, and 3-gram models.\n",
        "\n",
        "c) Analyze the results (Provide your own examples of spelling errors and calculate the probability of two similar sentences, where one has the correct word order and the other has an incorrect word order).\n"
      ],
      "metadata": {
        "id": "T-Gpi02VqMOE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzJ2VJMFMwBX"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY7-XncrRIPK",
        "outputId": "d133de6d-5844-4f65-cca5-2281a5f509e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgblFgcsGtPI",
        "outputId": "72acaa7b-a14b-4b9c-a61d-b113ca3f0d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "import contractions\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo1UXH9JN-9s"
      },
      "source": [
        "## Data Downloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HjDEZRnVM3Cv"
      },
      "outputs": [],
      "source": [
        "with open('/content/tedtalk.txt') as file:\n",
        "  docs = file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXec_f3WPfTn"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "BEM_WqqvPex8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8ee337-38f0-43be-fcf9-5548dfd6370b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words: 69371\n",
            "Number of tokens: 8718249\n"
          ]
        }
      ],
      "source": [
        "vocab = set()     # Number of unique word\n",
        "token_count = 0   # Number of token\n",
        "\n",
        "# Lower case character\n",
        "def text_lowercase(text):\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "# Split into sentences\n",
        "def sent_tokenize(text):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    return sentences\n",
        "\n",
        "# Removing contractions and Keep number, a to z and . ! ? character\n",
        "def remove_punctuation(text):\n",
        "    text = contractions.fix(text)\n",
        "    text = re.sub(r'[^a-z0-9.!?]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "# Tokenize the text into words\n",
        "def tokenize(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    return ['<s>'] + tokens + ['</s>']\n",
        "\n",
        "# Data preprocessing\n",
        "def preprocess_text(text):\n",
        "    global token_count\n",
        "    text = text_lowercase(text)\n",
        "    sentences = sent_tokenize(text)\n",
        "    processed_sentences = []\n",
        "    for sentence in sentences:\n",
        "      sentence = remove_punctuation(sentence)\n",
        "      sentence = tokenize(sentence)\n",
        "      token_count += len(sentence)\n",
        "      for token in sentence:\n",
        "        vocab.add(token)\n",
        "      processed_sentences.append(sentence)\n",
        "\n",
        "    return processed_sentences\n",
        "\n",
        "preprocess_data = preprocess_text(docs)\n",
        "print(\"Number of unique words:\", len(vocab))\n",
        "print(\"Number of tokens:\", token_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKmTJGkkWtsw"
      },
      "source": [
        "## Build a language model based on n-grams using the Laplace smoothing method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_XL1lOa6RJH9"
      },
      "outputs": [],
      "source": [
        "class NgramModel:\n",
        "    def __init__(self, n, v, token_count):\n",
        "      self.n = n\n",
        "      self.ngrams = Counter()\n",
        "      self.context = Counter()\n",
        "      self.vocab = v\n",
        "      self.token_count = token_count\n",
        "\n",
        "    # Train the model by counting n-grams and contexts\n",
        "    def train(self, corpus):\n",
        "      for tokens in corpus:\n",
        "         for i in range(len(tokens) - self.n + 1):\n",
        "          ngram = tuple(tokens[i:i+self.n]) # Create n-gram\n",
        "          self.ngrams[ngram] += 1\n",
        "          self.context[ngram[:-1]] += 1\n",
        "\n",
        "    # Calculate the probability of an n-gram using Laplace smoothing\n",
        "    def laplace_smoothing(self, ngram):\n",
        "      if self.n != 1:\n",
        "        return (self.ngrams[ngram] + 1) / (self.context[ngram[:-1]] + self.vocab)\n",
        "      else:\n",
        "        return (self.ngrams[ngram] + 1) / (self.token_count + self.vocab)\n",
        "\n",
        "    # Calculate the probability of a given sentence\n",
        "    def sentence_probability(self, sentence):\n",
        "      prob = 1\n",
        "      tokens = preprocess_text(sentence)[0]\n",
        "      for i in range(len(tokens) - self.n + 1):\n",
        "          ngram = tuple(tokens[i:i+self.n])\n",
        "          laplace = self.laplace_smoothing(ngram)\n",
        "          prob = prob * laplace\n",
        "      return prob\n",
        "\n",
        "    # Calculate the perplexity of a given sentence\n",
        "    def sentence_perplexity(self, sentence):\n",
        "      tokens = preprocess_text(sentence)[0]\n",
        "      N = len(tokens)\n",
        "      prob = self.sentence_probability(sentence)\n",
        "      return prob ** (-1 / N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekXhQvgh6Vse"
      },
      "source": [
        "## Calculate the probability of a sentence and compute the Perplexity of a sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Rp9IFB1u6bSd"
      },
      "outputs": [],
      "source": [
        "# Train unigram, bigram, and trigram model\n",
        "unigram_model = NgramModel(n=1, v=len(vocab), token_count=token_count)\n",
        "bigram_model = NgramModel(n=2, v=len(vocab), token_count=token_count)\n",
        "trigram_model = NgramModel(n=3, v=len(vocab), token_count=token_count)\n",
        "\n",
        "unigram_model.train(preprocess_data)\n",
        "bigram_model.train(preprocess_data)\n",
        "trigram_model.train(preprocess_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Wt3u_hvhG4mQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce1a1e4d-5416-446d-bf35-08d9a2e1fce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Model:\n",
            "  Probability of correct sentence: 6.525214922979809e-30\n",
            "  Perplexity of correct sentence: 270.4687527281362\n",
            "  Probability of incorrect sentence: 6.52521492297981e-30\n",
            "  Perplexity of incorrect sentence: 270.4687527281362\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Bigram Model:\n",
            "  Probability of correct sentence: 4.0739919098866776e-25\n",
            "  Perplexity of correct sentence: 107.77010843045838\n",
            "  Probability of incorrect sentence: 1.72312816050699e-30\n",
            "  Perplexity of incorrect sentence: 302.20863434985387\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Trigram Model:\n",
            "  Probability of correct sentence: 3.2913209604134965e-33\n",
            "  Perplexity of correct sentence: 509.1969735230111\n",
            "  Probability of incorrect sentence: 1.192217162207629e-40\n",
            "  Perplexity of incorrect sentence: 2123.0996850122556\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Sample sentences for evaluation\n",
        "correct_sentence = \"I want to give a speech at Ted Talk.\"\n",
        "incorrect_sentence = \"I want give a speech to at Ted Talk.\"\n",
        "\n",
        "# Calculate probabilities and perplexities of each sentence\n",
        "for model, name in zip([unigram_model, bigram_model, trigram_model], [\"Unigram\", \"Bigram\", \"Trigram\"]):\n",
        "    print(f\"{name} Model:\")\n",
        "    print(f\"  Probability of correct sentence: {model.sentence_probability(correct_sentence)}\")\n",
        "    print(f\"  Perplexity of correct sentence: {model.sentence_perplexity(correct_sentence)}\")\n",
        "\n",
        "    print(f\"  Probability of incorrect sentence: {model.sentence_probability(incorrect_sentence)}\")\n",
        "    print(f\"  Perplexity of incorrect sentence: {model.sentence_perplexity(incorrect_sentence)}\")\n",
        "    print(100*'-')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze the results\n",
        "- **Unigram Model:**\n",
        "  - Probability of correct and incorrect sentences is **identical** because unigrams treat words as independent without any context\n",
        "  - High perplexity (~270), indicating not very accurate at predicting the next word\n",
        "\n",
        "- **Bigram Model:**\n",
        "  - The correct sentence has a **higher probability** than the incorrect sentence due to consideration of word pairs\n",
        "  - Perplexity:\n",
        "    - Correct sentence: Lower (~107), meaning the model is more confident.\n",
        "    - Incorrect sentence: Higher (~302), showing the model can detect incorrect word order\n",
        "\n",
        "- **Trigram Model:**\n",
        "  - The correct sentence has a **significantly higher probability** than the incorrect sentence by capturing more context\n",
        "  - Perplexity:\n",
        "    - Correct sentence: Much higher (~509) since trigram required three-word sequence in the training data, however these trigrams are unseened in traning set due to the limiation of traning data, resulting in high perplexity\n",
        "    - Incorrect sentence: Extremely high (~2123) since a severe mismatch with training data, meaning many of trigrams don't exist in the training set\n"
      ],
      "metadata": {
        "id": "cmJt04YPn2Kj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}