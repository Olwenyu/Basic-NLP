{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1scE5rBNAR2G"
      },
      "source": [
        "# In-class Lab 2: Text Data Preprocessing\n",
        "**Overview:** In this lesson, we will build a text preprocessing pipeline for English text, which includes: data cleaning, converting to lowercase, removing punctuation, tokenization, removing stop words, and stemming. The exercise requires knowledge and programming skills in Python using libraries such as string, re, nltk, and numpy.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G8XZPuMAR2T"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8ijK-PShAR2V"
      },
      "outputs": [],
      "source": [
        "import string # used for preprocessing\n",
        "import re # used for preprocessing\n",
        "import nltk # the Natural Language Toolkit, used for preprocessing\n",
        "import numpy as np # used for managing NaNs\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords # used for preprocessing\n",
        "from nltk.stem import WordNetLemmatizer # used for preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0DQgAkWAR2W"
      },
      "source": [
        "## Question 1: Exploring the Dataset\n",
        "\n",
        "The raw text data that needs preprocessing is in the file \"wiki.txt\". This file contains short documents (docs), with each document on a separate line. In this question, we will explore the following:\n",
        "\n",
        "- The number of docs in the corpus\n",
        "- Observing a few docs from the corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GsbV9GSEAR2X",
        "outputId": "504b0243-b98e-47ab-cae0-75f27570c033",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of docs in the corpus: 2362\n",
            "\n",
            "A few docs from the corpus:\n",
            "1 : Madhuca utilis is a tree in the Sapotaceae family. It grows up to 40 metres (130 ft) tall, with a trunk diameter of up to 70 centimetres (28 in). The bark is greyish brown. The fruits are ellipsoid, up to 5.5 centimetres (2.2 in) long. The specific epithet utilis is from the Latin meaning \\\"useful\\\", referring to the timber. Habitat is swamps and lowland kerangas forests. M. utilis is found in Sumatra, Peninsular Malaysia and Borneo.\n",
            "\n",
            "2 : The Lycée Edmond Perrier (Edmond Perrier high school) is a general and technical secondary education institution, located in Tulle, Correze. It is dedicated to zoologist Edmond Perrier, born in Tulle in 1844. It was built by Anatole de Baudot, and has many similarities with the Lycée Lakanal, due to the same architect. His motto is \\\"Sint rupes virtutis iter\\\", identical to that of Tulle which means \\\"The difficulties are the path of virtue\\\".\n",
            "\n",
            "3 : Shareh Khvor (Persian: شره خور‎‎) is a village in Bask-e Kuleseh Rural District, in the Central District of Sardasht County, West Azerbaijan Province, Iran. At the 2006 census, its population was 14, in 4 families.\n",
            "\n",
            "4 : St. Rose Roman Catholic Church Complex is a Roman Catholic church complex located at Lima in Livingston County, New York. The complex consists of four contributing buildings: 1) St. Rose Church, constructed 1870-1873; 2) Brendan Hall, constructed in 1894 as a parochial school; 3) rectory; and 4) convent. It was listed on the National Register of Historic Places in 1988.\n",
            "\n",
            "5 : Langangen is a village in Porsgrunn municipality, Telemark county, in Norway. Langangen borders to Larvik municipality and Vestfold county. Its population is 499 (2009 Census). Langangen was earlier divided by European route E18 but in 1979 the road was led over Langangen bridge. Langangen has its own elementary school and chapel.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#### YOUR CODE HERE ####\n",
        "with open('/content/wiki.txt') as file:\n",
        "  docs = file.readlines()\n",
        "\n",
        "print('The number of docs in the corpus:', len(docs))\n",
        "print('\\nA few docs from the corpus:')\n",
        "for i, doc in enumerate(docs[:5], start=1):\n",
        "  print(i,':',doc)\n",
        "#### END YOUR CODE #####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDDZjv38-EGL"
      },
      "source": [
        "## Question 2: Building Text Processing Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6I8R30NAR2c"
      },
      "source": [
        "### Question 2.1: Building a Data Cleaning Function\n",
        "\n",
        "**Description:** The function removes digits and keeps only the characters \"A-Za-z(),!?\\'\\`\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "80LZzOxCAR2d"
      },
      "outputs": [],
      "source": [
        "# clean text\n",
        "def clean_text(text):\n",
        "    #### YOUR CODE HERE ####\n",
        "    text = re.sub(r'[^A-Za-z(),!?\\'\\`\\s]', '', text)\n",
        "    return text\n",
        "    #### END YOUR CODE #####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLyDqwtcAR2d"
      },
      "source": [
        "### Question 2.2: Function to Convert Text to Lowercase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v5N6q83DAR2e"
      },
      "outputs": [],
      "source": [
        "# make all text lowercase\n",
        "#### YOUR CODE HERE ####\n",
        "def text_lowercase(text):\n",
        "    text = text.lower()\n",
        "    return text\n",
        "#### END YOUR CODE #####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkzajg44AR2e"
      },
      "source": [
        "### Question 2.3: Building a Function to Remove Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lLFWvQRLAR2f"
      },
      "outputs": [],
      "source": [
        "# remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    #### YOUR CODE HERE ####\n",
        "    text = re.sub(r'[^a-zA-z0-9\\s]', '', text)\n",
        "    text = re.sub(r'[_\\[\\]]', '', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "    #### END YOUR CODE #####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ocSyA9AR2f"
      },
      "source": [
        "### Question 2.4: Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "33hwwyZaJyKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eca9cc3f-8d7e-48bf-f043-df0f1bfce4b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ru8lNWuDAR2g"
      },
      "outputs": [],
      "source": [
        "# tokenize\n",
        "def tokenize(text):\n",
        "    #### YOUR CODE HERE ####\n",
        "    return word_tokenize(text)\n",
        "    #### END YOUR CODE #####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L8rJildAR2g"
      },
      "source": [
        "### Question 2.5: Removing Stopwords\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASefNv2XKeSx",
        "outputId": "b65b980d-d2be-4dbe-af19-e1ca4a6e20aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-03fXud4AR2h"
      },
      "outputs": [],
      "source": [
        "# remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "#### YOUR CODE HERE ####\n",
        "def remove_stopwords(words):\n",
        "    token = [word for word in words if word not in stop_words]\n",
        "    return token\n",
        "#### END YOUR CODE #####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVXH3PorAR2h"
      },
      "source": [
        "### Question 2.6: Building a Lemmatization Function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkkubpdCNsfW",
        "outputId": "6d992f2e-004d-4b8d-c303-167762a0e28e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import wordnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1JoWF5mQWtH",
        "outputId": "3a106bf0-4821-4e51-ad8a-2c8374b47a5d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hNb3hemPAR2i"
      },
      "outputs": [],
      "source": [
        "# lemmatize\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "#### YOUR CODE HERE ####\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "def lemmatize(words):\n",
        "    pos_tags = pos_tag(words)\n",
        "    words = [lemmatizer.lemmatize(word, pos=get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
        "    return words\n",
        "#### END YOUR CODE #####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pr3h3J4AR2i"
      },
      "source": [
        "### Question 2.7: Building a Preprocessing Function\n",
        "**Hint:** This function will call the functions written above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lpM1j8v9AR2i"
      },
      "outputs": [],
      "source": [
        "def preprocessing(text):\n",
        "#### YOUR CODE HERE ####\n",
        "    text = clean_text(text)\n",
        "    text = text_lowercase(text)\n",
        "    text = remove_punctuation(text)\n",
        "    text = tokenize(text)\n",
        "    text = remove_stopwords(text)\n",
        "    text = lemmatize(text)\n",
        "    text = ' '.join(text)\n",
        "    return text\n",
        "\n",
        "#### END YOUR CODE #####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQJicZUrAR2j"
      },
      "source": [
        "## Question 3: Preprocessing for Input Text\n",
        "**Overview:** Using the functions above, preprocess the initial text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tSWwb3gsAR2j",
        "outputId": "6f7f93e5-c8e3-4ebf-e61c-48fdebdc287e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : madhuca utilis tree sapotaceae family grow metre ft tall trunk diameter centimetre bark greyish brown fruit ellipsoid centimetre long specific epithet utilis latin meaning useful refer timber habitat swamp lowland kerangas forest utilis find sumatra peninsular malaysia borneo\n",
            "2 : lyce edmond perrier edmond perrier high school general technical secondary education institution locate tulle correze dedicate zoologist edmond perrier bear tulle build anatole de baudot many similarity lyce lakanal due architect motto sint rupes virtutis iter identical tulle mean difficulty path virtue\n",
            "3 : shareh khvor persian village baske kuleseh rural district central district sardasht county west azerbaijan province iran census population family\n",
            "4 : st rise roman catholic church complex roman catholic church complex locate lima livingston county new york complex consist four contributing building st rise church construct brendan hall construct parochial school rectory convent list national register historic place\n",
            "5 : langangen village porsgrunn municipality telemark county norway langangen border larvik municipality vestfold county population census langangen earlier divide european route e road lead langangen bridge langangen elementary school chapel\n"
          ]
        }
      ],
      "source": [
        "#### YOUR CODE HERE ####\n",
        "preprocessed_docs = [preprocessing(doc) for doc in docs[:5]]\n",
        "for i, doc in enumerate(preprocessed_docs, start=1):\n",
        "  print(i, ':', doc)\n",
        "#### END YOUR CODE #####"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "labNLP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}